rm(ex3)
# remove unnecessary columns
tweets <- data.frame(tweets)
names <- c('screen_name', 'tweet_type', 'date', 'tweetid', 'rt_hashtag', 'hashtag')
tweets <- tweets[names]
# if hashtag contains 'qanon', 1 if not 0 (should be all 1)
tweets$hashtag_qanon <- ifelse(grepl('qanon', tweets$hashtag), 1, 0)
View(tweets)
table(tweets$hashtag_qanon)
# if tweet is original, 1 if not 0
tweets$original <- ifelse(grepl('original', tweets$tweet_type), 1, 0)
table(tweets$original)
# Identify time of first use of hashtag (original tweet)
# Convert time to epoch
tweets$date <- as.POSIXct(tweets$date, format = "%a %b %d %H:%M:%S %z %Y", tz = "GMT")
tweets$date <- lubridate::as_datetime(tweets$date)
tweets$date <- as.integer(tweets$date)
# find earliest tweet when original (first adoption)
times <- tweets %>%
group_by(screen_name) %>%
filter(original == 1) %>%
summarise(adoption_time = min(date, na.rm= TRUE))
times
joined_df <- merge(times, tweets, by = 'screen_name', all.y = T)
joined_df
View(joined_df)
# find how many exposures before adoption
# find tweets that were before adoption for users who adopted. This drops rows where original=1, so we have to make sure to add them back at the end.
temp <- joined_df %>%
filter(original == 0) %>%
mutate(time_difference = date - adoption_time)
View(temp)
View(tweets)
# if before, 1, ifelse 0
temp$difference <- ifelse(temp$time_difference < 0, 1, 0)
# count number of exposures before adoption
exposure_count <- temp %>%
filter(difference == 1) %>%
group_by(screen_name) %>%
count()
exposures <- merge(temp, exposure_count, by = 'screen_name', all.x = T)
View(exposures)
View(tweets)
# Now, the exposures df is missing rows where original=1. We add them back here
# add columns to joined_df that are in the exposures df
joined_df$time_difference <- NA
joined_df$difference <- NA
joined_df$n <- NA
joined_df <- joined_df %>% filter(original == 1)
final_df <- rbind(joined_df, exposures)
View(final_df)
here)-
here()
# Adoption threshold with retweet graph
# ------------------ Setup
# Read data
source('01-read_data.R')
# if hashtag contains 'qanon', 1 if not 0 (should be all 1)
tweets$hashtag_qanon <- ifelse(grepl('qanon', tweets$hashtag), 1, 0)
# if tweet is original, 1 if not 0
tweets$original <- ifelse(grepl('original', tweets$tweet_type), 1, 0)
# Identify time of first use of hashtag (original tweet)
# Convert time to epoch
tweets$date <- as.POSIXct(tweets$date, format = "%a %b %d %H:%M:%S %z %Y", tz = "GMT")
tweets$date <- lubridate::as_datetime(tweets$date)
tweets$date <- as.integer(tweets$date)
# find earliest tweet when original (first adoption)
times <- tweets %>%
group_by(screen_name) %>%
filter(original == 1) %>%
summarise(adoption_time = min(date, na.rm= TRUE))
joined_df <- merge(times, tweets, by = 'screen_name', all.y = T)
# find how many exposures before adoption
# find tweets that were before adoption for users who adopted. This drops rows where original=1, so we have to make sure to add them back at the end.
temp <- joined_df %>%
filter(original == 0) %>%
mutate(time_difference = date - adoption_time)
# if before, 1, ifelse 0
temp$difference <- ifelse(temp$time_difference < 0, 1, 0)
# count number of exposures before adoption
exposure_count <- temp %>%
filter(difference == 1) %>%
group_by(screen_name) %>%
count()
exposures <- merge(temp, exposure_count, by = 'screen_name', all.x = T)
# Now, the exposures df is missing rows where original=1. We add them back here
# add columns to joined_df that are in the exposures df
joined_df$time_difference <- NA
joined_df$difference <- NA
joined_df$n <- NA
joined_df <- joined_df %>% filter(original == 1)
final_df <- rbind(joined_df, exposures)
# Remove unnecessary data
rm(data)
rm(exposure_count)
rm(exposures)
rm(joined_df)
rm(temp)
rm(times)
rm(tweets)
# Descriptive statistics
# Read previous script
source('02-adoption_threshold.R')
here()
# Descriptive statistics
# Read previous script
source('/02-adoption_threshold.R')
# Descriptive statistics
# Read previous script
source('/02-adoption_threshold.R')
# Descriptive statistics
# Read previous script
source('02-adoption_threshold.R')
# Descriptive statistics
# Read previous script
source('02-adoption_threshold.R')
# Descriptive statistics
# Read previous script
source('02-adoption_threshold.R')
tweets <- final_df
# Number of adopters
count(tweets$tweet_type[tweets$tweet_type == 'original'])
tweets$tweet_type[tweets$tweet_type == 'original']
length(tweets$tweet_type[tweets$tweet_type == 'original'])
View(tweets)
tweets$n
length(tweets$n)
sum(tweets$n)
sum(tweets$n, na.rm = F)
sum(tweets$n, na.rm = T)
count((tweets$n, na.rm = T))
count(tweets$n, na.rm = T)
# Number of adopters without prior exposure
is.na(tweets$n)
# Number of adopters without prior exposure
!is.na(tweets$n)
# Number of adopters without prior exposure
sum(!is.na(tweets$n))
# Number of adopters
length(tweets$tweet_type[tweets$tweet_type == 'original'])
# average number of exposures needed to adopt
mean(tweets$n, na.rm = T)
3 + 3 + 3 + 1
10/4
# average number of exposures needed to adopt
# subset to unique users in data
unique(tweets)
# average number of exposures needed to adopt
# subset to unique users in data
unique(tweets$screen_name)
# average number of exposures needed to adopt
# subset to unique users in data
unique(tweets)
87 + 419
# average number of exposures needed to adopt
# subset to unique users in data
ex <- unique(tweets)
mean(ex$n, na.rm = T)
View(ex)
tweets %>%
filter(unique(screen_name))
ex <- tweets %>%
filter(unique(screen_name))
ex <- unique(tweets$screen_name)
ex
tweets %>%
filter(screen_name == ex)
temp <- tweets %>%
filter(screen_name == ex)
View(temp)
# average number of exposures needed to adopt
# subset to unique users in data
!is.na(tweets$n)
print('ok')
# average number of exposures needed to adopt
# subset to unique users in data
(!is.na(tweets$n)
)
# average number of exposures needed to adopt
# subset to unique users in data
ex <- !is.na(tweets$n
)
ex
# average number of exposures needed to adopt
# subset to unique users in data
ex <- !is.na(tweets$n)
match(ex, tweets)
?match
1:10 %in% c(1,3,5,9)
setdiff(tweets)
setdiff(tweets, final_df)
# average number of exposures needed to adopt
# subset to unique users in data
tweets[!duplicated(tweets[ , 'screen_name']), ]
# average number of exposures needed to adopt
# subset to unique users in data
temp <- tweets[!duplicated(tweets[ , 'screen_name']), ]
View(temp)
# average number of exposures needed to adopt
# assign values when tweet-type = original
tweets %>%
group_by(screen_name) %>%
summarise(n)
temp <- group_by(df, participant, day) %>%
mutate(age = as.numeric(as.character(likes[which(question == 0)])))
# average number of exposures needed to adopt
# assign values when tweet-type = original
temp <- tweets %>%
group_by(screen_name) %>%
summarise(n)
View(temp)
# average number of exposures needed to adopt
# assign values when tweet-type = original
temp <- tweets %>%
group_by(screen_name) %>%
summarise(exposures = n)
# average number of exposures needed to adopt
# assign values when tweet-type = original
temp <- tweets %>%
group_by(screen_name) %>%
mutate(exposures = n)
View(temp)
View(tweets)
user <- c(1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3)
score <- c(3, 3, 3, NA, 0, 0, 0, NA, NA, NA, NA, NA)
type <- c('new', 'recent', 'recent', 'old', 'recent', 'new', 'new', 'old', 'new', 'new', 'new', 'recent')
df <- data.frame(user, score, type)
df
df %>%
group_by(user) %>%
fill(score)
df %>%
group_by(user) %>%
fill(score) %>%
fill(score, .direction = "down")
df %>%
group_by(user) %>%
fill(score) %>%
fill(score, .direction = "up")
down
df %>%
group_by(user) %>%
fill(score) %>%
fill(score, .direction = "down")
# average number of exposures needed to adopt
# assign values when tweet-type = original
tweets %>%
group_by(screen_name) %>%
fill(n) %>%
fill(n, .direction = "down")
# average number of exposures needed to adopt
# assign values when tweet-type = original
tweets <- tweets %>%
group_by(screen_name) %>%
fill(n) %>%
fill(n, .direction = "down")
View(tweets)
tweets %>%
group_by(screen_name
)
# Descriptive statistics
# Read previous script
source('02-adoption_threshold.R')
here()
# Descriptive statistics
# Read previous script
source('02-adoption_threshold.R')
tweets %>%
group_by(screen_name)
tweets %>%
group_by(userid)
View(tweets)
# average number of exposures needed to adopt
# assign values when tweet-type = original
tweets <- tweets %>%
group_by(userid) %>%
fill(n) %>%
fill(n, .direction = "down")
View(tweets)
tweets %>%
group_by(userid) %>%
fill(n) %>% #default direction down
fill(n, .direction = "up")
tweets <- tweets %>%
group_by(userid) %>%
fill(n) %>% #default direction down
fill(n, .direction = "up")
View(tweets)
# subset to unique users in data
temp <- tweets[!duplicated(tweets[ , 'screen_name']), ]
View(temp)
tweets[!duplicated(tweets[ , 'screen_name']), ] $n
tweets[!duplicated(tweets[ , 'screen_name']), ]$n
mean(tweets[!duplicated(tweets[ , 'screen_name']), ]$n, na.rm = T)
rm(temp)
# average number of exposures needed to adopt
# subset to unique users in data
mean(tweets[!duplicated(tweets[ , 'screen_name']), ]$n, na.rm = T)
# Number of adopters
length(tweets$tweet_type[tweets$tweet_type == 'original'])
# Number of adopters with prior exposure
adopters_with_exposure <- sum(!is.na(tweets$n))
adopters_with_exposure
adopters_with_exposure
# Number of adopters without prior exposure
adopters_without_exposure <- nrow(tweets) - adopters_with_exposure
adopters_without_exposure
# Number of adopters without prior exposure
adopters_without_exposure <- length(tweets$tweet_type[tweets$tweet_type == 'original']) - adopters_with_exposure
adopters_without_exposure
adopters_with_exposure
tweets[!duplicated(tweets[ , 'screen_name']), ]
tweets[!duplicated(tweets[ , 'screen_name']) & tweets$tweet_type == 'original', ]
tweets$tweet_type[tweets$tweet_type == 'original']
tweets$tweet_type[tweets$tweet_type == 'original', ]
tweets$tweet_type[tweets$tweet_type == 'original']$n
tweets[tweets$tweet_type == 'original']
tweets$tweet_type == 'original'
!is.na(tweets$n)
sum(!is.na(tweets$n))
table(unique(tweets)$n)
table(unique(tweets)$n, tweets$screen_name)
table(tweets$n, tweets$screen_name)
table(tweets$n, unique(tweets$screen_name))
tweets %>%
distinct(n)
tweets %>%
distinct(n) %>%
group_by(screen_name)
colnames(tweets)
tweets %>%
distinct(n) %>%
group_by('screen_name')
tweets %>%
distinct(n) %>%
group_by('screen_name') %>%
summarize("agent in teams" = n())
tweets %>%
group_by(screen_name) %>%
unique(n)
tweets %>%
group_by(screen_name) %>%
distinct(n)
tweets %>%
group_by(screen_name) %>%
distinct(n) %>%
sum()
tweets %>%
group_by(screen_name) %>%
distinct(n) %>%
count()
ex <- tweets %>%
group_by(screen_name) %>%
distinct(n) %>%
# Number of adopters with prior exposure
adopters_with_exposure <- sum(!is.na(tweets$n))
ex <- tweets %>%
group_by(screen_name) %>%
distinct(n) %>%
# Number of adopters with prior exposure
adopters_with_exposure <- sum(!is.na(tweets$n))
ex <- tweets %>%
group_by(screen_name) %>%
distinct(n)
ex
unique(ex$n)
length(ex$n)
length(ex$n, na.rm = T)
colSums(!is.na(ex$n))
colSums(!is.na(ex))
colSums(!is.na(ex))[2]
colSums(!is.na(ex))[2][2]
colSums(!is.na(ex))[[2]]
# Number of adopters
length(tweets$tweet_type[tweets$tweet_type == 'original'])
adopters_with_exposure
tweets %>%
group_by(screen_name) %>%
distinct(n) %>%
colSums(!is.na(ex))[[2]]
tweets %>%
group_by(screen_name) %>%
distinct(n) %>%
colSums(!is.na())[[2]]
tweets %>%
group_by(screen_name) %>%
distinct(n) %>%
colSums(!is.na(tweets))[[2]]
tweets %>%
group_by(screen_name) %>%
distinct(n) %>%
colSums(!is.na())[[2]]
adopters_with_exposure
adopters_with_exposure <- tweets %>%
group_by(screen_name) %>%
distinct(n)
adopters_with_exposure <- colSums(!is.na(ex))[[2]]
adopters_with_exposure
# Number of adopters without prior exposure
adopters_without_exposure <- length(tweets$tweet_type[tweets$tweet_type == 'original']) - adopters_with_exposure
adopters_without_exposure
# average number of exposures needed to adopt
# subset to unique users in data
mean(tweets[!duplicated(tweets[ , 'screen_name']), ]$n, na.rm = T)
# including users who only adopt without exposure (assigned 0)
tweets_adopters <- ifelse(tweets$n == NA, 0, tweets$n)
# including users who only adopt without exposure (assigned 0)
tweets_adopters <- ifelse(tweets$n = NA, 0, tweets$n)
ifelse(tweets$n == NA, 0, tweets$n)
tweets$n
# including users who only adopt without exposure (assigned 0)
tweets_adopters <- tweets
tweets_adopters[is.na(tweets_adopters$n)] <- 0
tweets_adopters[is.na(tweets_adopters$n)]
tweets_adopters$n[is.na(tweets_adopters$n)] <- 0
View(tweets_adopters)
table(tweets_adopters$n)
# average number of exposures needed to adopt
# excluding sole-adopters (excluding users who only adopted)
mean(tweets[!duplicated(tweets[ , 'screen_name']), ]$n, na.rm = T)
mean(tweets_adopters[!duplicated(tweets_adopters[ , 'screen_name']), ]$n, na.rm = T)
# including users who only adopt without exposure (assigned 0)
tweets %>%
filter(tweet_type == 'original')
# including users who only adopt without exposure (assigned 0)
tweets %>%
filter(tweet_type == 'original') %>%
mean(tweets[!duplicated(tweets[ , 'screen_name']), ]$n, na.rm = T)
# including users who only adopt without exposure (assigned 0)
tweets_adopters %>%
filter(tweet_type == 'original') %>%
mean(tweets_adopters[!duplicated(tweets_adopters[ , 'screen_name']), ]$n, na.rm = T)
mean(tweets_adopters[!duplicated(tweets_adopters[ , 'screen_name']), ]$n, na.rm = T)
tweets_adopters <- tweets[tweets$tweet_type == 'original', ]
tweets_adopters$n[is.na(tweets_adopters$n)] <- 0
mean(tweets_adopters[!duplicated(tweets_adopters[ , 'screen_name']), ]$n, na.rm = T)
# average number of exposures needed to adopt
# excluding sole-adopters (excluding users who only adopted)
mean(tweets[!duplicated(tweets[ , 'screen_name']), ]$n, na.rm = T)
mean(tweets_adopters[!duplicated(tweets_adopters[ , 'screen_name']), ]$n, na.rm = T)    # compute mean
# Number of adopters with prior exposure
adopters_with_exposure <- tweets %>%
group_by(screen_name) %>%
distinct(n)
adopters_with_exposure
adopters_with_exposure
adopters_with_exposure <- colSums(!is.na(ex))[[2]]
adopters_with_exposure
rm(ex)
adopters_with_exposure
# Number of adopters with prior exposure
adopters_with_exposure <- tweets %>%
group_by(screen_name) %>%
distinct(n)
adopters_with_exposure
adopters_with_exposure <- colSums(!is.na(adopters_with_exposure))[[2]]
adopters_with_exposure
temp <- tweets %>%
group_by(screen_name) %>%
distinct(n)
temp
table(temp$n)
temp[1]
table(temp$n)
table(temp$n)[1]
table(temp$n)[1]
length(table(temp$n))
table(tweets$tweet_type)
length(table(tweets$tweet_type))
for(i in 1:length(table(tweets$tweet_type))){
print(i)
}
table(tweets$tweet_type)[1]
user <- c(1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3)
score <- c(3, 3, 3, NA, 0, 0, 0, NA, NA, NA, NA, NA)
type <- c('new', 'recent', 'recent', 'old', 'recent', 'new', 'new', 'old', 'new', 'new', 'new', 'recent')
df <- data.frame(user, score, type)
df
table(df$type)
table(temp$n)
table(tweets_adopters$n)
count(tweets_adopters$n)
count(tweets_adopters, 'n')
> install.packages('epiDisplay')
library(epiDisplay)
install.packages('epiDisplay')
library(epiDisplay)
tab1(tweets_adopters$n, sort.group = "decreasing", cum.percent = TRUE)
count(tweets, 'n')
count(tweets_adopters, 'n')
as.data.frame(table(tweets_adopters$n))
colnames(frequency_table)
# ------- Graph logarithm curve
# Compute frequency table
frequency_table <- as.data.frame(table(tweets_adopters$n))
# ------- Graph logarithm curve
# Compute frequency table
frequency_table <- as.data.frame(table(tweets_adopters$n))
colnames(frequency_table)
colnames(frequency_table)[1] <- 'Exposures'
colnames(frequency_table)[2] <- 'Frequency'
frequency_table
plot(frequency_table)
dev.off()
plot(frequency_table)
plot(frequency_table$Exposures, frequency_table$Frequency, main="Scatterplot Example",
xlab="Car Weight ", ylab="Miles Per Gallon ", pch=19)
ggplot(frequency_table, aes(x=Exposures, y=Exposures)) +
geom_point()
ggplot(frequency_table, aes(x=Exposures, y=Frequency)) +
geom_point()
dev.off()
