---
title: "Descriptive Statistics - POIR 613 Final Project"
author: "Bijean Ghafouri"
date: "11/11/2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos = "!H", out.extra = "", echo = TRUE)
```

# Introduction
### Project
In this report, I show preliminary results for my project on the spread of political extremism online. I paint a portrait of the efficiency of extremist persuasion on Twitter. To describe the persuasion of online extremism, I explore the context of \textit{adopting} extremist behavior. What does it take to adopt extremist political behavior? How does it compare to moderate behavior? Do online users need to be more or less persuaded in order to express extremist views? 



### Data
To answer these questions, I use a dataset published by Chen, Deb and Ferrara (2021) which includes all tweets related to the 2020 US Presidential election from early 2020 until the summer of 2021. These tweets were collected through keyword search using Twitter's API. From this dataset, I sample all tweets posted in June 2020. This represents a total of 67,181,551 tweets in English related to the election.



### Complex contagion
Modeling political behavior with complex contagion is suitable to understand the conditions under which agents adopt extremist behaviors. Complex contagion describes a learning process in which an agent requires \textit{social reinforcement} to adopt a behavior (Centola and Macy 2007). In order words, an individual adopts a behavior after multiple individuals in their social network already adopted this behavior. This process follows a logic of hearding, where an agent requires other agents to approve the behavior in order to legitimize and adopt it. 


Using complex contagion, I demonstrate that extremist behavior requires less exposure to adopt relative to other types of political behavior. My hypothesis is that holding exposure constant, users on Twitter are more likely to adopt extremist behavior than moderate behavior. 


An important assumption required under complex contagion is that the adoption of behavior is \textit{risky} (Fink et al. 2016). The agent requires social reinforcement to adopt the behavior because of the associated risk. The assumption of risk presents a puzzle for my theory. My theory posits that extremist content is more persuasive that moderate content. To confirm this expectation, I expect online users to require less exposure to adopt extremist behavior compared to moderate behavior. 

The assumption of risk in complex contagion thus presents a puzzle when applied in my theory. My empirical expectation that extremist adoption is \textit{less} risky than adopting moderate behavior is indeed counterintuitive. Theoretically, we should expect extremist behavior to be \textit{more} risky to adopt than moderate behavior. Although this is true, it is not necessarily at odds with my argument. The process of adopting political behavior is done incrementally. A moderate user will not suddenly adopt extremist behavior. Moderates will progressively adopt slightly more extreme behaviors through time. This progression towards the extreme, I argue, is more likely than the progression towards moderate politics. With this logic, the lower risk associated to extremist behavior adoption is theoretically sound. It is true that suddenly adopting extremist behavior is risky, and the agent is aware of how risky this is. However, when an agent slowly progresses towards extremism, they do not perceive the level of risk allowing for persuasion. 


### Exposure and adoption 
The literature on contagion effects offer multiple measures of behavior adoption, often limited by the nature of the data. For example, researchers using online social network graphs conceptualize adoption in a way that is observable with these data. In my project, I am limited with Twitter data. Following Fink et al. (2016), I use hashtags as a measure of adoption. My goal is to measure how many exposures to #qanon is required \textit{before} a user authors a tweet using #qanon. This hashtag is meant to conceptualize extremist behavior. I consider users who use #qanon in a tweets as adopting extremist political behavior. Furthermore, I consider users exposed to #qanon when they retweet, quote tweet or reply to a tweet using #qanon. 

Past studies model complex contagion in different ways (Fink et al. 2016). Researchers will measure at the time of adoption how many users followed had also adopted the behavior. We may consider this an implicit measure of complex contagion, where we assume exposure. We cannot be certain that users have witness their followers behavior. Prior exposure is thus not necessarily internalized by the user. For example, a user might follow 3 users who used #qanon before using the hashtag himself, but never actually saw them use that hashtag.

In this project, I use an explicit measure of complex contagion. As with the implicit measure, we know how many users followed adopted the behavior. Here, however, we also know that the user was directly exposed to the behavior, since they engaged with that behavior online. For example, if a user retweets, replies or quotes a tweet using #qanon, we consider this to be an explicit exposure. 

To model complex contagion, I count how many times a user was exposed to #qanon before using the hashtag. Out of the 67,181,551 tweets posted in June 2020 related to the US Presidential election, 351,108 tweets contained #qanon, authored from 83,867 unique users. Out of these tweets, only 4024 tweets were original, meaning that 4024 users used #qanon and adopted extremist behavior. 

Out of these 4024 users, only 1624 users were exposed to #qanon prior to adopting the behavior. This means that 2400 users in the sample used #qanon without prior exposure. 

Among users who required prior exposure to adopt extremist behavior (1624 users), we observe an average of 5.467 exposures prior to behavior adoption. Among the entire sample of 4024 users, the average is 2.206 exposures prior to behavior adoption. In other words, Twitter users who authored a tweet containing #qanon were exposed to tweets authored by other users they saw on their timeline about 2.2 times before they authored that tweet. 


It is important to mention that I do not measure exposures to #qanon after the first time a user adopts the behavior. I mark a difference between behavior adoption and extremist expression. That is, adoption measures the first time a user tweets with #qanon. Extremist expression measures the number of times a user tweets #qanon. It is possible that a single exposure enables a user to initially adopt the behavior, while they subsequently require far more exposures to express political extremism frequently. On the contrary, it is possible for a user to require multiple exposures to initially adopt the behavior, but subsequently use extremist hashtag frequently without exposures. Although this may be interesting to measure, I do not capture these possibilities in this report. 





# Data visualization  
Here, I show some density plots that demonstrate my preliminary results. 

```{r, message = F, warning=F, include = F}
library(pacman)
p_load(data.table, tidyverse, igraph, here, parallel, RColorBrewer)
tweets <- read_csv("tweets-qanon-clean.csv")

unique_users <- tweets %>% 
  distinct(screen_name, .keep_all = TRUE)

df_adopters <- unique_users[unique_users$tweet_type == 'original', ]
df_adopters[, 'n'][is.na(df_adopters[, 'n'])] <- 0
nrow(df_adopters)

df_adopters_exposed <- df_adopters[!df_adopters$n == 0, ]
nrow(df_adopters_exposed)
nrow(df_adopters[df_adopters$n == 0, ])
mean(df_adopters_exposed$n)
mean(df_adopters$n)


# -------  Plotting with reduced data, where 100+ is in one category
df_adopted_reduced <- df_adopters
df_adopted_reduced[, 'n'][df_adopted_reduced[, 'n'] > 100, ] <- 0
df_adopted_reduced_exposed <- df_adopted_reduced[df_adopted_reduced$n != 0, ]  
```



First, we can plot the density distribution of the number of exposures before adoption. This includes users who require 0 exposures, which represent 60% of the sample. 
```{r, echo = FALSE,  warning=F}
ggplot(data = df_adopters, 
       aes(x = n, fill = 'Red')) + 
  geom_density(alpha=0.3) + 
  ggtitle("Density plot of Tweet exposures before adopting #qanon") + 
  xlab('Exposures to #Qanon') + ylab("Density") + 
  theme_bw() + 
  guides(fill = FALSE) 
```



Next, let's consider users who required at least one exposure before using #qanon. 

```{r, echo = FALSE, warning=F}
ggplot(data = df_adopters_exposed, 
       aes(x = n, fill = 'Red')) + 
  geom_density(alpha=0.3) + 
  ggtitle("Excluding sole adopters - Density plot of Tweet exposures before adopting #qanon") + 
  xlab('Exposures to #Qanon') + ylab("Density") + 
  theme_bw() + 
  guides(fill = FALSE)
```



We notice that only a few users require more than 100 exposures to adopt the behavior. Let's exclude these users from our sample, considering users who required less than 100 exposures. 

```{r, echo = FALSE, warning=F}
ggplot(data = df_adopted_reduced, 
       aes(x = n, fill = 'Red')) + 
  geom_density(alpha=0.3) + 
  ggtitle("Reduced: Density plot of Tweet exposures before adopting #qanon") + 
  xlab('Exposures to #Qanon') + ylab("Density") + 
  theme_bw() + 
  guides(fill = FALSE) 
```




Finally, let us consider the same sample, but with users who again required at least one exposure before adoption. 
```{r, echo = FALSE, warning=F}
ggplot(data = df_adopted_reduced_exposed, 
       aes(x = n, fill = 'Red')) + 
  geom_density(alpha=0.3) + 
  ggtitle("Reduced: Excluding sole adopters - Density plot of Tweet exposures before adopting #qanon") + 
  xlab('Exposures to #Qanon') + ylab("Density") + 
  theme_bw() + 
  guides(fill = FALSE)
```
