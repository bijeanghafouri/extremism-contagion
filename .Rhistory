# Adoption threshold with retweet graph
# ----- Import data
# ------------------ Setup
library(pacman)
p_load(data.table, tidyverse, igraph, here)
p_load(data.table, tidyverse, igraph, here)
source('01-read_data.R')
source('01-read_data.R')
# clean hashtag
clean_tweets <- function(x) {
x %>%
# Remove URLs
str_remove_all(" ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)") %>%
# Remove mentions e.g. "@my_account"
str_remove_all("@[[:alnum:]_]{4,}") %>%
# Remove hashtags
str_remove_all("#[[:alnum:]_]+") %>%
# Replace "&" character reference with "and"
str_replace_all("&amp;", "and") %>%
# Remove punctucation, using a standard character class
str_remove_all("[[:punct:]]") %>%
# Remove "RT: " from beginning of retweets
str_remove_all("^RT:? ") %>%
# Replace any newline characters with a space
str_replace_all("\\\n", " ") %>%
# Make everything lowercase
str_to_lower() %>%
# Remove any trailing whitespace around the text
str_trim("both")
}
tweets$hashtag <- tweets$hashtag %>% clean_tweets
tweets$qtd_hashtag <- tweets$qtd_hashtag %>% clean_tweets
tweets$rt_hashtag <- tweets$rt_hashtag %>% clean_tweets
ex1 <- dplyr::filter(tweets, grepl("qanon", hashtag))
ex2 <- dplyr::filter(tweets, grepl("qanon", rt_hashtag))
ex3 <- dplyr::filter(tweets, grepl("qanon", qtd_hashtag))
tweets <- rbind(ex1, ex2, ex3)
rm(ex1)
rm(ex2)
rm(ex3)
# remove unnecessary columns
names <- c('screen_name', 'tweet_type', 'date', 'tweetid', 'rt_hashtag', 'hashtag')
tweets <- tweets[, names]
tweets <- tweets[, names]
tweets <- tweets[names]
tweets <- data.frame(tweets)
# remove unnecessary columns
names <- c('screen_name', 'tweet_type', 'date', 'tweetid', 'rt_hashtag', 'hashtag')
tweets <- tweets[names]
# Adoption threshold with retweet graph
# ------------------ Setup
# Read data
source('01-read_data.R')
# clean hashtag columns
clean_tweets <- function(x) {
x %>%
# Remove URLs
str_remove_all(" ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)") %>%
# Remove mentions e.g. "@my_account"
str_remove_all("@[[:alnum:]_]{4,}") %>%
# Remove hashtags
str_remove_all("#[[:alnum:]_]+") %>%
# Replace "&" character reference with "and"
str_replace_all("&amp;", "and") %>%
# Remove punctucation, using a standard character class
str_remove_all("[[:punct:]]") %>%
# Remove "RT: " from beginning of retweets
str_remove_all("^RT:? ") %>%
# Replace any newline characters with a space
str_replace_all("\\\n", " ") %>%
# Make everything lowercase
str_to_lower() %>%
# Remove any trailing whitespace around the text
str_trim("both")
}
tweets$hashtag <- tweets$hashtag %>% clean_tweets
tweets$qtd_hashtag <- tweets$qtd_hashtag %>% clean_tweets
tweets$rt_hashtag <- tweets$rt_hashtag %>% clean_tweets
# keep rows that have 'qanon' hashtag
ex1 <- dplyr::filter(tweets, grepl("qanon", hashtag))
ex2 <- dplyr::filter(tweets, grepl("qanon", rt_hashtag))
ex3 <- dplyr::filter(tweets, grepl("qanon", qtd_hashtag))
# bind temporary dataframes
tweets <- rbind(ex1, ex2, ex3)
# remove temporary dataframes
rm(ex1)
rm(ex2)
rm(ex3)
# Adoption threshold with retweet graph
# ------------------ Setup
# Read data
source('01-read_data.R')
# clean hashtag columns
clean_tweets <- function(x) {
x %>%
# Remove URLs
str_remove_all(" ?(f|ht)(tp)(s?)(://)(.*)[.|/](.*)") %>%
# Remove mentions e.g. "@my_account"
str_remove_all("@[[:alnum:]_]{4,}") %>%
# Remove hashtags
str_remove_all("#[[:alnum:]_]+") %>%
# Replace "&" character reference with "and"
str_replace_all("&amp;", "and") %>%
# Remove punctucation, using a standard character class
str_remove_all("[[:punct:]]") %>%
# Remove "RT: " from beginning of retweets
str_remove_all("^RT:? ") %>%
# Replace any newline characters with a space
str_replace_all("\\\n", " ") %>%
# Make everything lowercase
str_to_lower() %>%
# Remove any trailing whitespace around the text
str_trim("both")
}
tweets$hashtag <- tweets$hashtag %>% clean_tweets
tweets$qtd_hashtag <- tweets$qtd_hashtag %>% clean_tweets
tweets$rt_hashtag <- tweets$rt_hashtag %>% clean_tweets
# keep rows that have 'qanon' hashtag
ex1 <- dplyr::filter(tweets, grepl("qanon", hashtag))
ex2 <- dplyr::filter(tweets, grepl("qanon", rt_hashtag))
ex3 <- dplyr::filter(tweets, grepl("qanon", qtd_hashtag))
# bind temporary dataframes
tweets <- rbind(ex1, ex2, ex3)
# remove temporary dataframes
rm(ex1)
rm(ex2)
rm(ex3)
# remove unnecessary columns
tweets <- data.frame(tweets)
names <- c('screen_name', 'tweet_type', 'date', 'tweetid', 'rt_hashtag', 'hashtag')
tweets <- tweets[names]
# if hashtag contains 'qanon', 1 if not 0 (should be all 1)
tweets$hashtag_qanon <- ifelse(grepl('qanon', tweets$hashtag), 1, 0)
View(tweets)
table(tweets$hashtag_qanon)
# if tweet is original, 1 if not 0
tweets$original <- ifelse(grepl('original', tweets$tweet_type), 1, 0)
table(tweets$original)
# Identify time of first use of hashtag (original tweet)
# Convert time to epoch
tweets$date <- as.POSIXct(tweets$date, format = "%a %b %d %H:%M:%S %z %Y", tz = "GMT")
tweets$date <- lubridate::as_datetime(tweets$date)
tweets$date <- as.integer(tweets$date)
# find earliest tweet when original (first adoption)
times <- tweets %>%
group_by(screen_name) %>%
filter(original == 1) %>%
summarise(adoption_time = min(date, na.rm= TRUE))
times
joined_df <- merge(times, tweets, by = 'screen_name', all.y = T)
joined_df
View(joined_df)
# find how many exposures before adoption
# find tweets that were before adoption for users who adopted. This drops rows where original=1, so we have to make sure to add them back at the end.
temp <- joined_df %>%
filter(original == 0) %>%
mutate(time_difference = date - adoption_time)
View(temp)
View(tweets)
# if before, 1, ifelse 0
temp$difference <- ifelse(temp$time_difference < 0, 1, 0)
# count number of exposures before adoption
exposure_count <- temp %>%
filter(difference == 1) %>%
group_by(screen_name) %>%
count()
exposures <- merge(temp, exposure_count, by = 'screen_name', all.x = T)
View(exposures)
View(tweets)
# Now, the exposures df is missing rows where original=1. We add them back here
# add columns to joined_df that are in the exposures df
joined_df$time_difference <- NA
joined_df$difference <- NA
joined_df$n <- NA
joined_df <- joined_df %>% filter(original == 1)
final_df <- rbind(joined_df, exposures)
View(final_df)
here)-
here()
# Adoption threshold with retweet graph
# ------------------ Setup
# Read data
source('01-read_data.R')
# if hashtag contains 'qanon', 1 if not 0 (should be all 1)
tweets$hashtag_qanon <- ifelse(grepl('qanon', tweets$hashtag), 1, 0)
# if tweet is original, 1 if not 0
tweets$original <- ifelse(grepl('original', tweets$tweet_type), 1, 0)
# Identify time of first use of hashtag (original tweet)
# Convert time to epoch
tweets$date <- as.POSIXct(tweets$date, format = "%a %b %d %H:%M:%S %z %Y", tz = "GMT")
tweets$date <- lubridate::as_datetime(tweets$date)
tweets$date <- as.integer(tweets$date)
# find earliest tweet when original (first adoption)
times <- tweets %>%
group_by(screen_name) %>%
filter(original == 1) %>%
summarise(adoption_time = min(date, na.rm= TRUE))
joined_df <- merge(times, tweets, by = 'screen_name', all.y = T)
# find how many exposures before adoption
# find tweets that were before adoption for users who adopted. This drops rows where original=1, so we have to make sure to add them back at the end.
temp <- joined_df %>%
filter(original == 0) %>%
mutate(time_difference = date - adoption_time)
# if before, 1, ifelse 0
temp$difference <- ifelse(temp$time_difference < 0, 1, 0)
# count number of exposures before adoption
exposure_count <- temp %>%
filter(difference == 1) %>%
group_by(screen_name) %>%
count()
exposures <- merge(temp, exposure_count, by = 'screen_name', all.x = T)
# Now, the exposures df is missing rows where original=1. We add them back here
# add columns to joined_df that are in the exposures df
joined_df$time_difference <- NA
joined_df$difference <- NA
joined_df$n <- NA
joined_df <- joined_df %>% filter(original == 1)
final_df <- rbind(joined_df, exposures)
# Remove unnecessary data
rm(data)
rm(exposure_count)
rm(exposures)
rm(joined_df)
rm(temp)
rm(times)
rm(tweets)
# Descriptive statistics
# Read previous script
source('02-adoption_threshold.R')
here()
# Descriptive statistics
# Read previous script
source('/02-adoption_threshold.R')
# Descriptive statistics
# Read previous script
source('/02-adoption_threshold.R')
# Descriptive statistics
# Read previous script
source('02-adoption_threshold.R')
# Descriptive statistics
# Read previous script
source('02-adoption_threshold.R')
# Descriptive statistics
# Read previous script
source('02-adoption_threshold.R')
tweets <- final_df
# Number of adopters
count(tweets$tweet_type[tweets$tweet_type == 'original'])
tweets$tweet_type[tweets$tweet_type == 'original']
length(tweets$tweet_type[tweets$tweet_type == 'original'])
View(tweets)
tweets$n
length(tweets$n)
sum(tweets$n)
sum(tweets$n, na.rm = F)
sum(tweets$n, na.rm = T)
count((tweets$n, na.rm = T))
count(tweets$n, na.rm = T)
# Number of adopters without prior exposure
is.na(tweets$n)
# Number of adopters without prior exposure
!is.na(tweets$n)
# Number of adopters without prior exposure
sum(!is.na(tweets$n))
# Number of adopters
length(tweets$tweet_type[tweets$tweet_type == 'original'])
# average number of exposures needed to adopt
mean(tweets$n, na.rm = T)
3 + 3 + 3 + 1
10/4
# average number of exposures needed to adopt
# subset to unique users in data
unique(tweets)
# average number of exposures needed to adopt
# subset to unique users in data
unique(tweets$screen_name)
# average number of exposures needed to adopt
# subset to unique users in data
unique(tweets)
87 + 419
# average number of exposures needed to adopt
# subset to unique users in data
ex <- unique(tweets)
mean(ex$n, na.rm = T)
View(ex)
tweets %>%
filter(unique(screen_name))
ex <- tweets %>%
filter(unique(screen_name))
ex <- unique(tweets$screen_name)
ex
tweets %>%
filter(screen_name == ex)
temp <- tweets %>%
filter(screen_name == ex)
View(temp)
# average number of exposures needed to adopt
# subset to unique users in data
!is.na(tweets$n)
print('ok')
# average number of exposures needed to adopt
# subset to unique users in data
(!is.na(tweets$n)
)
# average number of exposures needed to adopt
# subset to unique users in data
ex <- !is.na(tweets$n
)
ex
# average number of exposures needed to adopt
# subset to unique users in data
ex <- !is.na(tweets$n)
match(ex, tweets)
?match
1:10 %in% c(1,3,5,9)
setdiff(tweets)
setdiff(tweets, final_df)
# average number of exposures needed to adopt
# subset to unique users in data
tweets[!duplicated(tweets[ , 'screen_name']), ]
# average number of exposures needed to adopt
# subset to unique users in data
temp <- tweets[!duplicated(tweets[ , 'screen_name']), ]
View(temp)
# average number of exposures needed to adopt
# assign values when tweet-type = original
tweets %>%
group_by(screen_name) %>%
summarise(n)
temp <- group_by(df, participant, day) %>%
mutate(age = as.numeric(as.character(likes[which(question == 0)])))
# average number of exposures needed to adopt
# assign values when tweet-type = original
temp <- tweets %>%
group_by(screen_name) %>%
summarise(n)
View(temp)
# average number of exposures needed to adopt
# assign values when tweet-type = original
temp <- tweets %>%
group_by(screen_name) %>%
summarise(exposures = n)
# average number of exposures needed to adopt
# assign values when tweet-type = original
temp <- tweets %>%
group_by(screen_name) %>%
mutate(exposures = n)
View(temp)
View(tweets)
user <- c(1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3)
score <- c(3, 3, 3, NA, 0, 0, 0, NA, NA, NA, NA, NA)
type <- c('new', 'recent', 'recent', 'old', 'recent', 'new', 'new', 'old', 'new', 'new', 'new', 'recent')
df <- data.frame(user, score, type)
df
df %>%
group_by(user) %>%
fill(score)
df %>%
group_by(user) %>%
fill(score) %>%
fill(score, .direction = "down")
df %>%
group_by(user) %>%
fill(score) %>%
fill(score, .direction = "up")
down
df %>%
group_by(user) %>%
fill(score) %>%
fill(score, .direction = "down")
# average number of exposures needed to adopt
# assign values when tweet-type = original
tweets %>%
group_by(screen_name) %>%
fill(n) %>%
fill(n, .direction = "down")
# average number of exposures needed to adopt
# assign values when tweet-type = original
tweets <- tweets %>%
group_by(screen_name) %>%
fill(n) %>%
fill(n, .direction = "down")
View(tweets)
tweets %>%
group_by(screen_name
)
# Descriptive statistics
# Read previous script
source('02-adoption_threshold.R')
here()
